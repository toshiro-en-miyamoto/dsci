<!DOCTYPE html>
<html lang="ja">
<head>
    <title>Probability</title>
    <link rel="stylesheet" href="stats-ml.css" type="text/css">
</head>
<body>

<h1>Hypothesis Test</h1>

<!-- ******************************************************************** -->
<h2>Random variables and probability distributions</h2>

<section id="random_variables" class="description">

<h3>Random Variable</h3>
<p>
The outcome of an experiment need not be a number, for example, the outcome when a coin is tossed can be 'heads' or 'tails'. However, we often want to represent outcomes as numbers. A random variable is a <u>function</u> that associates a unique numerical value with every outcome of an experiment. The value of the random variable will vary from trial to trial as the experiment is repeated.
</p>
<p>
There are two types of random variable - discrete and continuous.
A random variable has either an associated <i>probability distribution</i> (discrete random variable) or <i>probability density function</i> (continuous random variable).
</p>

<h3>確率分布 probability distribution</h3>
<p>
2個のサイコロを1000回振って毎回の出た目の和を記録するという実験を行った結果を表1の左半分に示す。
理論的に考察すると，目の和が最小であるのは，両方のサイコロが共に1の目が出たときであり，これは1&frasl;36 の確率であることが分かる。目の和が 3 になるのは，(1, 2)という出方と(2, 1)という出方の 2 通りであり 2&frasl;36 となる。これをまとめると表1の右半分になる。
</p>
<figure>
    <figcaption>表1．2個のサイコロを振る実験で出た目の和の分布と理論的な分布</figcaption>
    <table>
    <tr>
        <th>
            和
            <math>
                <msub>
                    <mi>x</mi>
                    <mi>i</mi>
                </msub>
            </math>
        </th>
        <th>
            度数
        </th>
        <th>
            相対度数
        </th>
        <th>
            累計相対度数
        </th>
        <th>
            確率
            <math>
                <mi>f</mi>
                <mo fence="true">&lpar;</mo>
                <msub>
                    <mi>x</mi>
                    <mi>i</mi>
                </msub>
                <mo fence="true">&rpar;</mo>
            </math>
        </th>
        <th>
            分布関数
            <math>
                <mi>F</mi>
                <mo fence="true">&lpar;</mo>
                <msub>
                    <mi>x</mi>
                    <mi>i</mi>
                </msub>
                <mo fence="true">&rpar;</mo>
            </math>
        </th>
    </tr>
    <tr>
        <td>2</td>
        <td>23</td>
        <td>0.023</td>
        <td>0.023</td>
        <td>1&frasl;36=0.028</td>
        <td>1&frasl;36=0.028</td>
    </tr>
    <tr>
        <td>3</td>
        <td>48</td>
        <td>0.048</td>
        <td>0.071</td>
        <td>2&frasl;36=0.056</td>
        <td>3&frasl;36=0.083</td>
    </tr>
    <tr>
        <td>4</td>
        <td>90</td>
        <td>0.090</td>
        <td>0.161</td>
        <td>3&frasl;36=0.083</td>
        <td>6&frasl;36=0.167</td>
    </tr>
    <tr>
        <td>5</td>
        <td>101</td>
        <td>0.101</td>
        <td>0.262</td>
        <td>4&frasl;36=0.111</td>
        <td>10&frasl;36=0.278</td>
    </tr>
    <tr>
        <td>6</td>
        <td>158</td>
        <td>0.158</td>
        <td>0.420</td>
        <td>5&frasl;36=0.139</td>
        <td>15&frasl;36=0.417</td>
    </tr>
    <tr>
        <td>7</td>
        <td>160</td>
        <td>0.160</td>
        <td>0.580</td>
        <td>6&frasl;36=0.167</td>
        <td>21&frasl;36=0.583</td>
    </tr>
    <tr>
        <td>8</td>
        <td>135</td>
        <td>0.135</td>
        <td>0.715</td>
        <td>5&frasl;36=0.139</td>
        <td>26&frasl;36=0.722</td>
    </tr>
    <tr>
        <td>9</td>
        <td>122</td>
        <td>0.122</td>
        <td>0.837</td>
        <td>4&frasl;36=0.111</td>
        <td>30&frasl;36=0.833</td>
    </tr>
    <tr>
        <td>10</td>
        <td>87</td>
        <td>0.087</td>
        <td>0.924</td>
        <td>3&frasl;36=0.083</td>
        <td>33&frasl;36=0.917</td>
    </tr>
    <tr>
        <td>11</td>
        <td>50</td>
        <td>0.050</td>
        <td>0.974</td>
        <td>2&frasl;36=0.056</td>
        <td>35&frasl;36=0.972</td>
    </tr>
    <tr>
        <td>12</td>
        <td>26</td>
        <td>0.026</td>
        <td>1.000</td>
        <td>1&frasl;36=0.028</td>
        <td>36&frasl;36=1.000</td>
    </tr>
    <tr>
        <td>合計</td>
        <td>1000</td>
        <td>1.000</td>
        <td></td>
        <td>1.000</td>
        <td></td>
    </tr>
    </table>
</figure>
<p>
累積相対度数は経験的分布関数であり，その極限的なものが理論的分布関数
    <math>
        <mi>F</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <msub>
            <mi>x</mi>
            <mi>i</mi>
        </msub>
        <mo fence="true">&rpar;</mo>
    </math>
である（略して分布関数あるいは確率分布）。
</p>

<h3>Probability Distribution</h3>
<p>
The probability distribution of a discrete random variable is a list of probabilities associated with each of its possible values. It is also sometimes called the probability function or the probability mass function.
</p>

<h3>Cumulative Distribution Function</h3>
<p>
All random variables (discrete and continuous) have a cumulative distribution function. It is a function giving the probability that the random variable
    <math><mi>X</mi></math>
is less than or equal to
    <math><mi>x</mi></math>,
for every value
    <math><mi>x</mi></math>.
</p>
<p>
Example &mdash; discreate case:
Suppose a random variable
    <math><mi>X</mi></math>
has the following probability distribution
    <math>
        <mi>p</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <msub>
            <mi>x</mi>
            <mi>i</mi>
        </msub>
        <mo fence="true">&rpar;</mo>
    </math>:
</p>
<figure>
    <table>
        <tr>
            <th>
                <math>
                    <msub>
                        <mi>x</mi>
                        <mi>i</mi>
                    </msub>
                </math>
            </th>
            <th>0</th>
            <th>1</th>
            <th>2</th>
            <th>3</th>
            <th>4</th>
            <th>5</th>
        </tr>
        <tr>
            <th>
                <math>
                    <mi>p</mi>
                    <mo>&ApplyFunction;</mo>
                    <mo fence="true">&lpar;</mo>
                    <msub>
                        <mi>x</mi>
                        <mi>i</mi>
                    </msub>
                    <mo fence="true">&rpar;</mo>
                </math>
            </th>
            <td>1&frasl;32</td>
            <td>5&frasl;32</td>
            <td>10&frasl;32</td>
            <td>10&frasl;32</td>
            <td>5&frasl;32</td>
            <td>2&frasl;32</td>
        </tr>
    </table>
</figure>
<p>
The cumulative distribution function
    <math>
        <mi>F</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
            <mi>x</mi>
        <mo fence="true">&rpar;</mo>
    </math>
is then:
</p>
<figure>
    <table>
        <tr>
            <th>
                <math>
                    <msub>
                        <mi>x</mi>
                        <mi>i</mi>
                    </msub>
                </math>
            </th>
            <th>0</th>
            <th>1</th>
            <th>2</th>
            <th>3</th>
            <th>4</th>
            <th>5</th>
        </tr>
        <tr>
            <th>
                <math>
                    <mi>F</mi>
                    <mo>&ApplyFunction;</mo>
                    <mo fence="true">&lpar;</mo>
                    <msub>
                        <mi>x</mi>
                        <mi>i</mi>
                    </msub>
                    <mo fence="true">&rpar;</mo>
                </math>
            </th>
            <td>1&frasl;32</td>
            <td>6&frasl;32</td>
            <td>16&frasl;32</td>
            <td>26&frasl;32</td>
            <td>31&frasl;32</td>
            <td>32&frasl;32</td>
        </tr>
    </table>
</figure>

<h3>Probability Density Function</h3>
<p>
The probability density function of a continuous random variable is a function which can be integrated to obtain the probability that the random variable takes a value in a given interval.

More formally, the probability density function,
    <math>
        <mi>f</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
            <mi>x</mi>
        <mo fence="true">&rpar;</mo>
    </math>,
of a continuous random variable
    <math>
        <mi>X</mi>
    </math>
is the derivative of the cumulative distribution function
    <math>
        <mi>F</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
            <mi>x</mi>
        <mo fence="true">&rpar;</mo>
    </math>:
</p>
<figure>
    <math>
        <mi>f</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
            <mi>x</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mrow>
            <mfrac>
                <mo>&PartialD;</mo>
                <mrow>
                    <mo>&PartialD;</mo>
                    <mi>x</mi>
                </mrow>
            </mfrac>
            <mo>&ApplyFunction;</mo>
            <mi>F</mi>
            <mo>&ApplyFunction;</mo>
            <mo fence="true">&lpar;</mo>
                <mi>x</mi>
            <mo fence="true">&rpar;</mo>
        </mrow>
    </math>
</figure>
<p>
the total probability for all possible values of the continuous random variable X is 1:
</p>
<figure>
    <math>
        <mo>&Integral;</mo>
        <mi>f</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
            <mi>x</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&InvisibleTimes;</mo>
        <mrow>
            <mo>&PartialD;</mo>
            <mi>x</mi>
        </mrow>
        <mo>&equals;</mo>
        <mn>1</mn>
    </math>
</figure>

<h3>中心極限定理 central limit theorem</h3>
<p>
平均値
    <math><mi>&mu;</mi></math>，
分散
    <math>
        <msup>
            <mi>&sigma;</mi>
            <mn>2</mn>
        </msup>
    </math>
をもつ，任意の分布に従う乱数列
    <math>
        <msub>
            <mi>x</mi>
            <mn>1</mn>
        </msub>
        <mo separator="true">&comma;</mo>
        <msub>
            <mi>x</mi>
            <mn>2</mn>
        </msub>
        <mo separator="true">&comma;</mo>
        <mi>&hellip;</mi>
        <mo separator="true">&comma;</mo>
        <msub>
            <mi>x</mi>
            <mi>n</mi>
        </msub>
    </math>
があるとき，その平均値
</p>
<figure>
    <math displaystyle="true">
        <mrow>
            <msub>
                <mover>
                    <mi>x</mi>
                    <mo>&OverBar;</mo>
                </mover>
                <mi>n</mi>
            </msub>
        </mrow>
        <mo>&equals;</mo>
        <mrow>
            <mfrac>
                <mrow>
                    <msub>
                        <mi>x</mi>
                        <mn>1</mn>
                    </msub>
                    <mo>&plus;</mo>
                    <msub>
                        <mi>x</mi>
                        <mn>2</mn>
                    </msub>
                    <mo>&plus;</mo>
                    <mi>&hellip;</mi>
                    <mo>&plus;</mo>
                    <msub>
                        <mi>x</mi>
                        <mi>n</mi>
                    </msub>
                </mrow>
                <mi>n</mi>
            </mfrac>
        </mrow>
    </math>
</figure>
<p>
の確率分布は，
    <math><mi>n</mi></math>
が大きくなるとき，平均値
    <math><mi>&mu;</mi></math>，
分散
    <math displaystyle="true">
        <mfrac>
            <msup>
                <mi>&sigma;</mi>
                <mn>2</mn>
            </msup>
            <mi>n</mi>
        </mfrac>
    </math>
である正規分布に収束する。
</p>

<h3>Central Limit Theorem</h3>
<p>
The Central Limit Theorem states that whenever a random sample of size
    <math><mi>n</mi></math>
is taken from any distribution with mean
    <math><mi>&mu;</mi></math>
and variance
    <math>
        <msup>
            <mi>&sigma;</mi>
            <mn>2</mn>
        </msup>
    </math>,
then the sample mean
    <math>
        <mover>
            <mi>x</mi>
            <mi>&OverBar;</mi>
        </mover>
    </math>
will be approximately normally distributed with mean
    <math><mi>&mu;</mi></math>
and variance
    <math>
        <msup>
            <mi>&sigma;</mi>
            <mn>2</mn>
        </msup>
        <mo>&frasl;</mo>
        <mi>n</mi>
    </math>.
The larger the value of the sample size
    <math><mi>n</mi></math>,
the better the approximation to the normal.
</p>
<p>
This is very useful when it comes to inference. For example, it allows us (if the sample size is fairly large) to use hypothesis tests which assume normality even if our data appear non-normal. This is because the tests use the sample mean
    <math>
        <mover>
            <mi>x</mi>
            <mi>&OverBar;</mi>
        </mover>
    </math>,
which the Central Limit Theorem tells us will be approximately normally distributed.
</p>

<h3>正規分布 normal distribution</h3>
<p>
確率密度関数が
</p>
<figure>
    <math displaystyle="true">
        <mi>f</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>x</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mfrac>
            <mn>1</mn>
            <mrow>
                <msqrt>
                    <mn>2</mn>
                    <mo>&InvisibleTimes;</mo>
                    <mi>&pi;</mi>
                </msqrt>
                <mo>&InvisibleTimes;</mo>
                <mi>&sigma;</mi>
            </mrow>
        </mfrac>
        <mo>&InvisibleTimes;</mo>
        <mi>exp</mi>
        <mo>&ApplyFunction;</mo>
        <mrow>
            <mo fence="true">&lbrace;</mo>
            <mo>&minus;</mo>
            <mfrac>
                <msup>
                    <mrow>
                        <mo fence="true">&lpar;</mo>
                        <mi>x</mi>
                        <mo>&minus;</mo>
                        <mi>&mu;</mi>
                        <mo fence="true">&rpar;</mo>
                    </mrow>
                    <mn>2</mn>
                </msup>
                <mrow>
                    <mn>2</mn>
                    <mo>&InvisibleTimes;</mo>
                    <msup>
                        <mi>&sigma;</mi>
                        <mn>2</mn>
                    </msup>
                </mrow>
            </mfrac>
            <mo fence="true">&rbrace;</mo>
        </mrow>
    </math>
</figure>
<p>
で表される確率分布。これを、平均
    <math><mi>&mu;</mi></math>、
分散
    <math>
        <msup>
            <mi>&sigma;</mi>
            <mn>2</mn>
        </msup>
    </math>
の正規分布といい、記号
    <math>
        <mrow>
            <mi>N</mi>
            <mo>&ApplyFunction;</mo>
            <mo fence="true">&lpar;</mo>
            <mi>&mu;</mi>
            <mo separator="true">&comma;</mo>
            <msup>
                <mi>&sigma;</mi>
                <mn>2</mn>
            </msup>
            <mo fence="true">&rpar;</mo>
        </mrow>
    </math>
で表す。単峰性で平均
    <math><mi>&mu;</mi></math>
を中心に左右対称な形状を示す。誤差の分布など自然界の多くの事象の分布モデルとして使用される。
</p>

<h3>Normal Distribution</h3>
<p>
Normal distributions model (some) continuous random variables. Strictly, a Normal random variable should be capable of assuming any value on the real line, though this requirement is often waived in practice. For example, height at a given age for a given gender in a given racial group is adequately described by a Normal random variable even though heights must be positive.
</p>
<p>
A continuous random variable
    <math><mi>X</mi></math>,
taking all real values in the range
    <math>
        <mrow>
            <mo fence="true">&lpar;</mo>
            <mo>&minus;</mo><mi>&infin;</mi>
            <mo separator="true">&comma;</mo>
            <mi>&infin;</mi>
            <mo fence="true">&rpar;</mo>
        </mrow>
    </math>
is said to follow a Normal distribution with parameters
    <math><mi>&mu;</mi></math>
and
    <math><mi>&sigma;</mi></math>
if it has probability density function
</p>
<figure>
    <math displaystyle="true">
        <mi>f</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>x</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mfrac>
            <mn>1</mn>
            <mrow>
                <mi>&sigma;</mi>
                <mo>&InvisibleTimes;</mo>
                <msqrt>
                    <mn>2</mn>
                    <mo>&InvisibleTimes;</mo>
                    <mi>&pi;</mi>
                </msqrt>
            </mrow>
        </mfrac>
        <mo>&InvisibleTimes;</mo>
        <mi>exp</mi>
        <mo>&ApplyFunction;</mo>
        <mrow>
            <mo fence="true">&lbrace;</mo>
            <mo>&minus;</mo>
            <mfrac>
                <mn>1</mn>
                <mn>2</mn>
            </mfrac>
            <mo>&InvisibleTimes;</mo>
            <msup>
                <mrow>
                    <mo fence="true">&lpar;</mo>
                    <mfrac>
                        <mrow>
                            <mi>x</mi>
                            <mo>&minus;</mo>
                            <mi>&mu;</mi>
                        </mrow>
                        <mi>&sigma;</mi>
                    </mfrac>
                    <mo fence="true">&rpar;</mo>
                </mrow>
                <mn>2</mn>
            </msup>
            <mo fence="true">&rbrace;</mo>
        </mrow>
    </math>
</figure>
<p>
We write
    <math>
        <mrow>
            <mi>X</mi>
            <mo>&Tilde;</mo>
            <mi>N</mi>
            <mo>&ApplyFunction;</mo>
            <mo fence="true">&lpar;</mo>
            <mi>&mu;</mi>
            <mo separator="true">&comma;</mo>
            <msup>
                <mi>&sigma;</mi>
                <mn>2</mn>
            </msup>
            <mo fence="true">&rpar;</mo>
        </mrow>
    </math>.
</p>

<h3>二項分布 binomial distribution</h3>
<p>
ある集団において，特性Aを持つものの割合が
    <math><mi>p</mi></math>
であり，持たないものの割合が
    <math><mi>q</mi></math>
であるとする（
    <math>
        <mi>p</mi>
        <mo>&plus;</mo>
        <mi>q</mi>
        <mo>&equals;</mo>
        <mn>1</mn>
    </math>
）。
このとき，集団から無作為に
    <math><mi>n</mi></math>
人を抽出したとき，特性Aを持つものが
    <math><mi>x</mi></math>
人である確率を考える。
    <math><mi>n</mi></math>
人のうち
    <math><mi>x</mi></math>
人が特性を持つ組合せは
    <math>
        <mmultiscripts>
            <mi>C</mi>
            <mi>x</mi><none/>
            <mprescripts/>
            <mi>n</mi><none/>
        </mmultiscripts>
    </math>
通りある（
    <math>
        <mo fence="true">&lpar;</mo>
        <mfrac linethickness="0">
            <mi>n</mi>
            <mi>x</mi>
        </mfrac>
        <mo fence="true">&rpar;</mo>
    </math>
とも書く） 。その各々に対して，
    <math><mi>x</mi></math>
人が特性Aを持つ確率は
    <math>
        <msup>
            <mi>p</mi>
            <mi>x</mi>
        </msup>
    </math>
，残り
    <math>
        <mi>n</mi>
        <mo>&minus;</mo>
        <mi>x</mi>
    </math>
人が特性を持たない確率は
    <math>
        <msup>
            <mi>q</mi>
            <mrow>
                <mi>n</mi>
                <mo>&minus;</mo>
                <mi>x</mi>
            </mrow>
        </msup>
    </math>
であり，両者が共に起こる確率は両者の積である。よって，
</p>
<figure>
    <math displaystyle="true">
        <mrow>
            <mi>f</mi>
            <mo>&ApplyFunction;</mo>
            <mo fence="true">&lpar;</mo>
            <mi>x</mi>
            <mo fence="true">&rpar;</mo>
        </mrow>
        <mo>&equals;</mo>
        <mrow>
            <mmultiscripts>
                <mi>C</mi>
                <mi>x</mi><none/>
                <mprescripts/>
                <mi>n</mi><none/>
            </mmultiscripts>
            <mo>&InvisibleTimes;</mo>
            <msup>
                <mi>p</mi>
                <mi>x</mi>
            </msup>
            <mo>&InvisibleTimes;</mo>
            <msup>
                <mi>q</mi>
                <mrow>
                    <mi>n</mi>
                    <mo>&minus;</mo>
                    <mi>x</mi>
                </mrow>
            </msup>
        </mrow>
    </math>
</figure>
<p>
が求める確率であり，この分布を二項分布と呼ぶ。この分布を
    <math>
        <mi>B</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>n</mi>
        <mo separator="true">&comma;</mo>
        <mi>p</mi>
        <mo fence="true">&rpar;</mo>
    </math>
と表すことにする。
</p>

<h3>Binomial distribution</h3>
<p>
In probability theory and statistics, the binomial distribution with parameters
    <math><mi>n</mi></math>
and
    <math><mi>p</mi></math>
is the discrete probability distribution of the number of successes in a sequence of
    <math><mi>n</mi></math>
independent experiments, each asking a yes–no question, and each with its own Boolean-valued outcome: success (with probability
    <math><mi>n</mi></math>
) or failure (with probability
    <math>
        <mi>q</mi>
        <mo>&equals;</mo>
        <mn>1</mn>
        <mo>&minus;</mo>
        <mi>p</mi>
    </math>
).
</p>
<p>
The binomial distribution is frequently used to model the number of successes in a sample of size
    <math><mi>n</mi></math>
drawn with replacement from a population of size
    <math><mi>N</mi></math>.
</p>
<p>
In general, if the random variable
    <math><mi>X</mi></math>
follows the binomial distribution with parameters
    <math>
        <mi>n</mi>
        <mo>&in;</mo>
        <mi>&naturals;</mi>
    </math>
and
    <math>
        <mi>p</mi>
        <mo>&in;</mo>
        <mo fence="true">&lsqb;</mo>
        <mn>0</mn>
        <mo separator="true">&comma;</mo>
        <mn>1</mn>
        <mo fence="true">&rsqb;</mo>
    </math>,
we write
    <math>
        <mi>X</mi>
        <mo>&Tilde;</mo>
        <mi>B</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>n</mi>
        <mo separator="true">&comma;</mo>
        <mi>p</mi>
        <mo fence="true">&rpar;</mo>
    </math>.
The probability of getting exactly
    <math><mi>k</mi></math>
successes in
    <math><mi>n</mi></math>
independent <i>Bernoulli trials</i> (a single success/failure experiment) is given by the probability mass function:
</p>
<figure>
    <math displaystyle="true">
        <mrow>
            <mi>f</mi>
            <mo>&ApplyFunction;</mo>
            <mo fence="true">&lpar;</mo>
            <mi>k</mi>
            <mo separator="true">&comma;</mo>
            <mi>n</mi>
            <mo separator="true">&comma;</mo>
            <mi>p</mi>
            <mo fence="true">&rpar;</mo>
        </mrow>
        <mo>&equals;</mo>
        <mrow>
            <mi>Pr</mi>
            <mo>&ApplyFunction;</mo>
            <mo fence="true">&lpar;</mo>
            <mi>k</mi>
            <mo separator="true">&semi;</mo>
            <mi>n</mi>
            <mo separator="true">&comma;</mo>
            <mi>p</mi>
            <mo fence="true">&rpar;</mo>
        </mrow>
        <mo>&equals;</mo>
        <mrow>
            <mi>Pr</mi>
            <mo>&ApplyFunction;</mo>
            <mo fence="true">&lpar;</mo>
            <mi>X</mi>
            <mo>&equals;</mo>
            <mi>k</mi>
            <mo fence="true">&rpar;</mo>
        </mrow>
        <mo>&equals;</mo>
        <mrow>
            <mo fence="true">&lpar;</mo>
            <mfrac linethickness="0">
                <mi>n</mi>
                <mi>k</mi>
            </mfrac>
            <mo fence="true">&rpar;</mo>
            <mo>&InvisibleTimes;</mo>
            <msup>
                <mi>p</mi>
                <mi>k</mi>
            </msup>
            <mo>&InvisibleTimes;</mo>
            <msup>
                <mrow>
                    <mo fence="true">&lpar;</mo>
                    <mn>1</mn>
                    <mo>&minus;</mo>
                    <mi>p</mi>
                    <mo fence="true">&rpar;</mo>
                </mrow>
                <mrow>
                    <mi>n</mi>
                    <mo>&minus;</mo>
                    <mi>k</mi>
                </mrow>
            </msup>
        </mrow>
    </math>
</figure>
<p>
for
    <math>
        <mi>k</mi>
        <mo>&equals;</mo>
        <mn>0</mn>
        <mo>&comma;</mo>
        <mn>1</mn>
        <mo>&comma;</mo>
        <mn>2</mn>
        <mo>&comma;</mo>
        <mi>&hellip;</mi>
        <mo>&comma;</mo>
        <mi>n</mi>,
    </math>
where
    <math>
        <mo fence="true">&lpar;</mo>
        <mfrac linethickness="0">
            <mi>n</mi>
            <mi>k</mi>
        </mfrac>
        <mo fence="true">&rpar;</mo>
    </math>
is the <i>binomial coefficient</i>, hence the name of the distribution. The formula can be understood as follows:
    <math><mi>k</mi></math>
successes occur with probability
    <math>
        <msup>
            <mi>p</mi>
            <mi>k</mi>
        </msup>
    </math>
and
    <math>
        <mi>n</mi>
        <mo>&minus;</mo>
        <mi>k</mi>
    </math>
failures occur with probability
    (1 − p)n − k.
    <math>
        <msup>
            <mrow>
                <mn>1</mn>
                <mo>&minus;</mo>
                <mi>p</mi>
            </mrow>
            <mrow>
                <mi>n</mi>
                <mo>&minus;</mo>
                <mi>k</mi>
            </mrow>
        </msup>
    </math>.
However, the
    <math><mi>k</mi></math>
successes can occur anywhere among the
    <math><mi>n</mi></math>
trials, and there are
    <math>
        <mo fence="true">&lpar;</mo>
        <mfrac linethickness="0">
            <mi>n</mi>
            <mi>k</mi>
        </mfrac>
        <mo fence="true">&rpar;</mo>
    </math>
different ways of distributing
    <math><mi>k</mi></math>
successes in a sequence of
    <math><mi>n</mi></math>
trials.
</p>

<h3>ベルヌーイ試行 Bernoulli trials</h3>
<p>
1回ごとの事象の生起確率
    <math><mi>p</mi></math>
が一定であるとき，実験を繰り返し行うことをベルヌーイ試行というが，独立に実験を
    <math><mi>n</mi></math>
回繰り返したとき，
    <math><mi>x</mi></math>
回事象が生じる確率は二項分布である。このため二項分布はベルヌーイ分布とも呼ばれる。
</p>

<h3>ポアソン分布 Poisson distribution</h3>
<p>
「自動車事故による死亡が1年間に1万人であるとする。日本の人口を11,600万人，ある都市の人口を100万人としたとき，その都市で自動車事故による死亡が一件もないという日が起こる確率を求めよ。」
</p>
<p>
ある一人の人が交通事故にあう1日あたりの確率
    <math><mi>p</mi></math>
はきわめて小さい。
</p>
<figure>
    <math displaystyle="true">
        <mi>p</mi>
        <mo>&equals;</mo>
        <mfrac>
            <mrow>
                <mn>10,000</mn>
            </mrow>
            <mrow>
                <mn>116,000,000</mn>
                <mo>&times;</mo>
                <mn>365</mn>
            </mrow>
        </mfrac>
        <mo>&equals;</mo>
        <mn>2.362</mn>
        <mo>&times;</mo>
        <msup>
            <mn>10</mn>
            <mrow>
                <mo>&minus;</mo>
                <mn>7</mn>
            </mrow>
        </msup>
    </math>
</figure>
<p>
また，この都市の人口はきわめて大きいので，交通事故死の確率はポアソン分布に従うと考えられる。
</p>
<figure>
    <math displaystyle="true">
        <mi>f</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>x</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mrow>
            <mfrac>
                <mrow>
                    <msup>
                        <mi>&escr;</mi>
                        <mrow>
                            <mo>&minus;</mo>
                            <mi>&lambda;</mi>
                        </mrow>
                    </msup>
                    <mo>&InvisibleTimes;</mo>
                    <msup>
                        <mi>&lambda;</mi>
                        <mi>x</mi>
                    </msup>
                </mrow>
                <mrow>
                    <mi>x</mi>
                    <mo>&excl;</mo>
                </mrow>
            </mfrac>
        </mrow>
    </math>
</figure>
<p>
ポアソン分布のパラメータ
    <math><mi>&lambda;</mi></math>
は，
</p>
<figure>
    <math>
        <mi>&lambda;</mi>
        <mo>&equals;</mo>
        <mi>n</mi>
        <mo>&InvisibleTimes;</mo>
        <mi>p</mi>
        <mo>&equals;</mo>
        <mn>1,000,000</mn>
        <mo>&times;</mo>
        <mn>2.362</mn>
        <mo>&times;</mo>
        <msup>
            <mn>10</mn>
            <mrow>
                <mo>&minus;</mo>
                <mn>7</mn>
            </mrow>
        </msup>
        <mo>&equals;</mo>
        <mn>0.2362</mn>
    </math>
</figure>
<p>
求める確率は
    <math>
        <mi>f</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mn>0</mn>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mn>0.790</mn>
    </math>
となる。
</p>
<p>
このほか，ポアソン分布に当てはまる事象としては，製品中の不良品の個数，一定時間内に電話がかかってくる回数などがあげられる。
</p>

<h3>Poisson Distribution</h3>
<p>
Typically, a Poisson random variable is a count of the number of events that occur in a certain time interval or spatial area. For example,
</p>
<ul>
    <li>
        the number of cars passing a fixed point in a 5 minute interval, or
    </li>
    <li>
        the number of calls received by a switchboard during a given period of time.
    </li>
</ul>
<p>
A discrete random variable
    <math><mi>X</mi></math>
is said to follow a Poisson distribution with parameter
    <math><mi>m</mi></math>,
written
    <math>
        <mi>X</mi>
        <mo>&Tilde;</mo>
        <mi>Po</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>m</mi>
        <mo fence="true">&rpar;</mo>
    </math>,
if it has probability distribution
</p>
<figure>
    <math displaystyle="true">
        <mi>P</mi>
        <mo fence="true">&lpar;</mo>
        <mi>X</mi>
        <mo>&equals;</mo>
        <mi>x</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mfrac>
            <msup>
                <mi>m</mi>
                <mi>x</mi>
            </msup>
            <mrow>
                <mi>x</mi>
                <mo>&excl;</mo>
            </mrow>
        </mfrac>
        <mo>&InvisibleTimes;</mo>
        <msup>
            <mi>&escr;</mi>
            <mrow>
                <mo>&minus;</mo>
                <mi>m</mi>
            </mrow>
        </msup>
    </math>
</figure>
<p>
The Poisson distribution has expected value
    <math>
        <mi>E</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>X</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mi>m</mi>
    </math>
and variance
    <math>
        <mi>V</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>X</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mi>m</mi>
    </math>;
i.e.
    <math>
        <mi>E</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>X</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mi>V</mi>
        <mo>&ApplyFunction;</mo>
        <mo fence="true">&lpar;</mo>
        <mi>X</mi>
        <mo fence="true">&rpar;</mo>
        <mo>&equals;</mo>
        <mi>m</mi>
    </math>.
</p>
<p>
The Poisson distribution can sometimes be used to <u>approximate the Binomial distribution</u> with parameters
    <math><mi>n</mi></math>
and
    <math><mi>p</mi></math>.
When the number of observations
    <math><mi>n</mi></math>
is large, and the success probability
    <math><mi>p</mi></math>
is small, the
    <math>
        <mi>Bi</mi>
        <mo>&ApplyFunction;</mo>
        <mo fece="true">&lpar;</mo>
        <mi>n</mi>
        <mo separator="true">&comma;</mo>
        <mi>p</mi>
        <mo fence="true">&rpar;</mo>
    </math>
distribution approaches the Poisson distribution with the parameter given by
    <math>
        <mi>m</mi>
        <mo>&equals;</mo>
        <mi>n</mi>
        <mo>&InvisibleTimes;</mo>
        <mi>p</mi>
    </math>.
This is useful since the computations involved in calculating binomial probabilities are greatly reduced.
</p>

</section>

<!-- ******************************************************************** -->
<h2>Hypothesis test</h2>

<section id="hypothesis_testing" class="description">

<h3>仮説検定 hypothesis test</h3>
<p>
研究者はある理論から予想される事実を証明するために，調査または実験を行い，データを収集する。
この際の作業仮説（または実験仮説）を<i>対立仮説</i>
    <math>
        <msub>
            <mi>H</mi>
            <mn>1</mn>
        </msub>
    </math>
(<i>alternative hypothesis</i>)
とする。
例えば，“新しく開発された薬剤は，従来薬より有効である”とか，“男と女で読書時間に差がある”というのが対立仮説である。
</p>
<p>
これに対して，作業仮説を否定する仮説を<i>帰無仮説</i>
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>
(<i>null hypothesis</i>)
とする。
例えば，前の例では，“新しく開発された薬剤は，従来薬より有効とはいえない”とか，“男と女で読書時間に差はない”というのが帰無仮説である。
</p>
<p>
仮説検定の対象となるのは帰無仮説である。帰無仮説が棄却されれば対立仮説が支持されることになり，帰無仮説が棄却されて始めて研究者の調査・実験意図が達せられるわけで，この意味で 帰無仮説（無に帰される仮説）と呼ばれる。
</p>

<h3>Hypothesis Test</h3>
<p>
Setting up and testing hypotheses is an essential part of statistical inference. In order to formulate such a test, usually some theory has been put forward, either because it is believed to be true or because it is to be used as a basis for argument, but has not been proved, for example, claiming that a new drug is better than the current drug for treatment of the same symptoms.
</p>
<p>
In each problem considered, the question of interest is simplified into two competing claims / hypotheses between which we have a choice; the <i>null hypothesis</i>, denoted
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>,
against the <i>alternative hypothesis</i>, denoted
    <math>
        <msub>
            <mi>H</mi>
            <mn>1</mn>
        </msub>
    </math>.
</p>
<p>
The hypotheses are often statements about population parameters like <i>expected value</i> and <i>variance</i>; for example
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>
might be that the expected value of the height of ten year old boys in the Scottish population is not different from that of ten year old girls.
</p>
<p>
The outcome of a hypothesis test test is "Reject
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>
in favour of
    <math>
        <msub>
            <mi>H</mi>
            <mn>1</mn>
        </msub>
    </math>"
or "Do not reject
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>".
We never conclude "Reject
    <math>
        <msub>
            <mi>H</mi>
            <mn>1</mn>
        </msub>
    </math>",
or even "Accept
    <math>
        <msub>
            <mi>H</mi>
            <mn>1</mn>
        </msub>
    </math>".
</p>
<p>
If we conclude "Do not reject
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>",
this does not necessarily mean that the null hypothesis is true, it only suggests that there is not sufficient evidence against
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>
in favour of
    <math>
        <msub>
            <mi>H</mi>
            <mn>1</mn>
        </msub>
    </math>.
Rejecting the null hypothesis then, suggests that the alternative hypothesis may be true.
</p>

<h3>有意確率 p-value</h3>
<p>
統計的仮説検定において，帰無仮説のもとで得られた検定統計量が実現する確率。例えば，正規分布において標準得点が1.96以上となる確率は2.5%。有意確率がまえもって定めた<i>有意水準</i>より小さい場合に帰無仮説を棄却し，大きい場合に帰無仮説を採択する。
</p>

<h3>有意水準 level of significance; significance level</h3>
<p>
統計的仮説検定を行う場合に，帰無仮説を棄却するかどうかを判定する基準5%あるいは1%がよく使用される。有意水準5%で検定を行うということは，<i>第1種の過誤</i>をおかす確率（または危険率）が5%であることを意味する。すなわち，同様の調査・検定を行うと，20回に1回は得られた結論が誤っていることを表す。「有意水準αで検定すると有意な差が認められた」ということと，「危険率αのもとで有意な差があるといえる」は同じような意味で使用される。
</p>

<h3>第1種の過誤 type I error</h3>
<p>
帰無仮説が正しいにもかかわらず帰無仮説を棄却するという誤り。
</p>

<h3>第2種の過誤 type II error</h3>
<p>
帰無仮説が誤っているにもかかわらず帰無仮説を採択するという誤り。
</p>

<h3>P-Value</h3>
<p>
The probability value (p-value) of a statistical hypothesis test is the probability of getting a value of the test statistic as extreme as or more extreme than that observed by chance alone, if the null hypothesis
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>,
is true. It is the probability of wrongly rejecting the null hypothesis if it is in fact true.
</p>
<p>
It is equal to the <i>significance level</i> of the test for which we would only just reject the null hypothesis. The p-value is compared with the actual significance level of our test and, if it is smaller, the result is significant. That is, if the null hypothesis were to be rejected at the 5% signficance level, this would be reported as
    <math>
        <mrow>
            <mi>p</mi>
            <mo>&lt;</mo>
            <mn>0.05</mn>
        </mrow>
    </math>.
</p>
<p>
Small p-values suggest that the null hypothesis is unlikely to be true. The smaller it is, the more convincing is the rejection of the null hypothesis. It indicates the strength of evidence for say, rejecting the null hypothesis
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>,
rather than simply concluding "Reject
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>"
or "Do not reject
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>".
</p>

<h3>Significance Level</h3>
<p>
The significance level of a statistical hypothesis test is a fixed probability of wrongly rejecting the null hypothesis
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>,
if it is in fact true.
</p>
<p>
It is the probability of a <i>type I error</i> and is set by the investigator in relation to the consequences of such an error. That is, we want to make the significance level as small as possible in order to protect the null hypothesis and to prevent, as far as possible, the investigator from inadvertently making false claims.
Usually, the significance level is chosen to be 0.05 (or equivalently, 5%).
</p>

<h3>Type I Error</h3>
<p>
In a hypothesis test, a type I error occurs when the null hypothesis is rejected when it is in fact true; that is,
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>
is wrongly rejected.
</p>
<p>
For example, in a clinical trial of a new drug, the null hypothesis might be that the new drug is no better, on average, than the current drug; i.e.
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>:
there is no difference between the two drugs on average.
A type I error would occur if we concluded that the two drugs produced different effects when in fact there was no difference between them.
</p>
<p>
A type I error is often considered to be more serious, and therefore more important to avoid, than a <i>type II error</i>. The hypothesis test procedure is therefore adjusted so that there is a guaranteed 'low' probability of rejecting the null hypothesis wrongly; this probability is never 0.
</p>

<h3>Type II Error</h3>
<p>
In a hypothesis test, a type II error occurs when the null hypothesis H0, is not rejected when it is in fact false. For example, in a clinical trial of a new drug, the null hypothesis might be that the new drug is no better, on average, than the current drug; i.e.
    <math>
        <msub>
            <mi>H</mi>
            <mn>0</mn>
        </msub>
    </math>:
there is no difference between the two drugs on average.
A type II error would occur if it was concluded that the two drugs produced the same effect, i.e. there is no difference between the two drugs on average, when in fact they produced different ones.
</p>

</section>

</html>
</body>
